#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import print_function

import itertools as it, operator as op, functools as ft
from glob import glob
from fnmatch import fnmatch
from hashlib import sha1
from time import sleep
import os, sys, re, pickle, types, unicodedata

from twisted.python.filepath import FilePath
from twisted.internet import inotify, reactor, defer, error
from twisted.python import log

import dbus # gi.Notify seem to break when daemon instance exits



_notifier = None

def notify( path, line,
		icon='', actions=list(), hints=dict(),
		timeout=-1, retries=4, delay=0.3 ):
	line = re.sub( r'\d{4}-\d{2}-\d{2}T(\d{2}:){2}\d{2}(\.\d+)'
			r'?(\+|-)\d{2}:\d{2} (?P<channel>[\w.]+)(<\d+>)? (?P<msg>.*)$',
		r'\g<channel> \g<msg>', line )
	# Slow, can probably be optimized by compiling all these chars into a regexp
	line = u''.join( c for c in line.decode('utf-8', 'replace')
		if not unicodedata.category(c).startswith('C') ).encode('utf-8')
	global _notifier
	while True:
		if retries <= 0:
			try: reactor.stop()
			except error.ReactorNotRunning: pass
			else: log.fatal('Unable to use dbus for notifications, exiting')
			break
		if not _notifier:
			try:
				_notifier = dbus.Interface(
					dbus.SessionBus().get_object(
						'org.freedesktop.Notifications',
						'/org/freedesktop/Notifications' ),
					dbus_interface='org.freedesktop.Notifications' )
			except dbus.exceptions.DBusException:
				retries -= 1
				sleep(delay)
				continue
		try:
			_notifier.Notify( 'logtail_notify', 0, icon,
				'log: {}'.format(path.basename()), line, actions, hints, timeout )
		except dbus.exceptions.DBusException as err:
			if retries < 0 or err.get_dbus_name() not in\
				[ 'org.freedesktop.DBus.Error.ServiceUnknown',
					'org.freedesktop.DBus.Error.Disconnected' ]: raise
			_notifier = None # force reconnection
			retries -= 1
		else: break



class ReliableInotify(inotify.INotify):

	def __init__( self, paths_watch, callback, errback,
			mask=inotify.IN_CREATE | inotify.IN_MODIFY ):
		inotify.INotify.__init__(self)

		# Might as well start it here
		self.startReading()
		self.errback = errback
		for path in paths_watch:
			log.debug('Adding watcher for path: {}'.format(path))
			self.watch(path, mask=mask, callbacks=[callback])

	def connectionLost(self, reason):
		log.warn( 'Detected inotify'
			' connectionLost event, reason: {}'.format(reason) )
		self.errback(reason)



class Logtail(object):


	def __init__( self, monitor, callback,
			exclude=None, keep_pos=False,
			processing_delay=1.0, xattr_name='user.bordercamp.logtail.pos' ):
		self.callback, self.processing_delay, self.xattr_name =\
			callback, processing_delay, xattr_name

		self.exclude = exclude or list()
		if isinstance(self.exclude, types.StringTypes): self.exclude = [self.exclude]
		self.exclude = map(re.compile, self.exclude)

		paths_watch = self.paths_watch = dict()
		self.paths_pos, self.paths_buff = dict(), dict()

		masks, paths = monitor, list()
		if isinstance(masks, bytes): masks = [masks]
		for mask in masks:
			mask_patterns = self.glob_alter(mask)
			for mask_raw in mask_patterns:
				mask = FilePath(mask_raw)
				# All matched parent dirs - like /x/y/z for /x/*/z/file* - are watched for pattern
				# Note that watchers won't be auto-added for /x/m/z, if it'll be created later on
				paths_ext = list( (path.realpath(), mask.basename())
					for path in it.imap(FilePath, glob(mask.dirname())) )
				paths.extend(paths_ext)
				# If full pattern already match something, watch it if it's a dir - /x/dir1 for /x/dir*
				# Note that watchers won't be auto-added for /x/dir2, if it'll be created later on
				if paths_ext: # no point going deeper if parent dirs don't exist
					paths.extend( (path.realpath(), '*')
						for path in it.imap(FilePath, glob(mask_raw))
						if path.realpath().isdir() )
		# Aggregate path masks by-realpath
		for path, mask in paths:
			if not path.isdir():
				log.debug('Skipping special path: {}'.format(path))
				continue
			if path not in paths_watch:
				paths_watch[path] = {mask}
			else: paths_watch[path].add(mask)

		if not keep_pos:
			for path_dir, paths in paths_watch.viewitems():
				for path in paths: self.discard_changes(path_dir.child(path))

		self.notifier_restart()

	def notifier_restart(self, reason=None):
		log.debug('Starting inotify watcher')
		# errback happens if some IOError gets raised in a direct callback
		self.notifier = ReliableInotify( self.paths_watch,
			ft.partial( reactor.callLater, self.processing_delay,
				self.handle_change ), self.notifier_restart )


	@staticmethod
	def glob_alter(pattern, _glob_cbex = re.compile(r'\{[^}]+\}')):
		'''Shell-like glob with support for curly braces.
			Usage of these braces in the actual name isn't supported.'''
		subs = list()
		while True:
			ex = _glob_cbex.search(pattern)
			if not ex: break
			subs.append(ex.group(0)[1:-1].split(','))
			pattern = pattern[:ex.span()[0]] + '{}' + pattern[ex.span()[1]:]
		return list(it.starmap(pattern.format, it.product(*subs)))

	@staticmethod
	def file_end_mark(path, size=200, pos=None, data=None):
		if not pos:
			with path.open() as src:
				if not data:
					pos = None
					while pos != src.tell(): # to ensure that file didn't grow in-between
						pos = os.fstat(src.fileno()).st_size
						src.seek(-min(pos, size), os.SEEK_END)
						data = src.read()
				else:
					pos = os.fstat(src).st_size
		size, data = len(data), sha1(data).hexdigest()
		return pos, size, data

	@staticmethod
	def file_end_check(path, pos, size=None, data_hash=None):
		if pos != path.getsize(): return False
		elif size and data_hash:
			with path.open() as src: # lots of races ahead, but whatever
				src.seek(-size, os.SEEK_END)
				data = src.read(size)
				if len(data) != size: return False # not the end
				if sha1(data).hexdigest() != data_hash: return False # not the *same* end
		return True


	def discard_changes(self, path): self.handle_change(None, path)

	def handle_change(self, stuff, path, mask=None):
		if mask:
			mask_str = inotify.humanReadableMask(mask)
			log.debug('Event: {} ({})'.format(path, mask_str))

		## Filtering
		path_real = path.realpath()
		if not path_real.isfile():
			log.debug( 'Ignoring event for'
				' non-regular file: {} (realpath: {})'.format(path, path_real) )
			return
		dir_key = path_real.parent().realpath()
		if dir_key not in self.paths_watch:
			log.warn( 'Ignoring event for file outside of watched'
				' set of paths: {} (realpath: {})'.format(path, path_real) )
			return
		for pat in self.paths_watch[dir_key]:
			if fnmatch(bytes(path.basename()), pat): break
		else:
			log.debug( 'Non-matched path in one of'
				' the watched dirs: {} (realpath: {})'.format(path, path_real) )
			return
		for pat in self.exclude:
			if pat.search(path.path):
				log.debug( 'Matched path by exclude-pattern'
					' ({}): {} (realpath: {})'.format(pat, path, path_real) )
				return

		## Get last position
		pos = self.paths_pos.get(path_real)
		if not pos: # try restoring it from xattr
			try: pos = pickle.loads(xattr(path_real.path)[self.xattr_name])
			except KeyError:
				log.debug('Failed to restore last log position from xattr for path: {}'.format(path))
			else:
				log.debug(
					'Restored pos from xattr ({}) for path {}: {!r}'\
					.format(self.xattr_name, path_real, pos) )
		if pos:
			pos, size, data_hash = pos
			if self.file_end_check(path_real, pos, size=size, data_hash=data_hash):
				if mask:
					log.debug(( 'Event (mask: {}) for unchanged'
						' path, ignoring: {}' ).format(mask_str, path))
				return
			if path_real.getsize() < pos:
				log.debug( 'Detected truncation'
					' of a path, rewinding: {}'.format(path) )
				pos = None

		## Actual processing
		buff_agg = self.paths_buff.setdefault(path_real, '')
		with path_real.open() as src:
			if pos:
				src.seek(pos)
				pos = None
			while True:
				pos = src.tell()
				try: buff, pos = self.read(src), src.tell()
				except StopIteration:
					buff_agg = ''
					src.seek(pos) # revert back to starting position
					buff, pos = self.read(src), src.tell()
				if not buff: # eof, try to mark the position
					if not buff_agg: # clean eof at the end of the chunk - mark it
						pos = self.file_end_mark(path_real, pos=pos, data=buff_agg)
						self.paths_pos[path_real] = pos
						xattr(path_real.path)[self.xattr_name] = pickle.dumps(pos)
						log.debug( 'Updated xattr ({}) for path {} to: {!r}'\
							.format(self.xattr_name, path_real, pos) )
					break
				buff_agg = self.paths_buff[path_real] = self.process(
					buff_agg + buff, path, supress_callback=mask is None )

	def read(self, src):
		'Read however much is necessary for process() method'
		return src.readline()

	def process(self, buff, path, supress_callback=False):
		'Process buffered/read data, returning leftover buffer'
		if buff.endswith('\n'):
			line = buff.strip()
			log.debug('New line: {!r}'.format(line))
			if not supress_callback: self.callback(path, line)
			return ''
		else:
			return buff



def main():
	import argparse
	parser = argparse.ArgumentParser(
		description='Monitor given log paths for changes,'
			' creating desktop notifications for new lines.')
	parser.add_argument('monitor', nargs='+', help='Glob patterns for paths to monitor.')
	parser.add_argument('--exclude', action='append',
		default=list(), help='Regexps to match against paths to exclude from monitoring.')
	parser.add_argument('-i', '--icon', help='Icon to use for notifications.')
	parser.add_argument('-x', '--xattr-db',
		help='Path to shelve-db to use instead of xattrs to record file position.')
	parser.add_argument('--keep-pos',
		help='Start reading file from last-recorded position, not from the end.')
	parser.add_argument('--debug',
		action='store_true', help='Verbose operation mode.')
	optz = parser.parse_args()

	import logging
	logging.basicConfig(
		level=logging.DEBUG if optz.debug else logging.WARNING )
	log.PythonLoggingObserver().start()
	for lvl in 'debug', 'info', ('warning', 'warn'), 'error', ('critical', 'fatal'):
		lvl, func = lvl if isinstance(lvl, tuple) else (lvl, lvl)
		assert not getattr(log, lvl, False)
		setattr(log, func, ft.partial( log.msg,
			logLevel=logging.getLevelName(lvl.upper()) ))

	global xattr
	if not optz.xattr_db:
		from xattr import xattr
	else:
		import shelve
		xattr_db = shelve.open(optz.xattr_db, 'c')
		class xattr(object):
			def __init__(self, base):
				assert isinstance(base, str)
				self.base = base
			def key(self, k): return '{}\0{}'.format(self.base, k)
			def __setitem__(self, k, v): xattr_db[self.key(k)] = v
			def __getitem__(self, k): return xattr_db[self.key(k)]
			def __del__(self): xattr_db.sync()

	note_attrs = dict()
	if optz.icon: note_attrs['icon'] = optz.icon
	tailer = Logtail( optz.monitor, ft.partial(notify, **note_attrs),
		keep_pos=optz.keep_pos, exclude=optz.exclude )

	log.debug('Starting event loop')
	reactor.run()

if __name__ == '__main__': main()
