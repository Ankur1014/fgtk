#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import print_function

import itertools as it, operator as op, functools as ft
from contextlib import closing
from collections import deque
from datetime import datetime
from threading import Event
import os, sys, re, signal

import requests

p = lambda fmt,*a,**k: print(fmt.format(*a,**k), file=sys.stderr)
try:
	import pyaml
	pp = lambda data: pyaml.dump(data, sys.stderr)
except ImportError:
	from pprint import pprint as pp


def find_frame_n(chunk0=None, chunk1=None):
	'''Locates start of adts frame as close to the middle of chunk0 as possible.
		Presumably stream title changes between chunk0
			and chunk1, so new track is expected to start somewhere in chunk0.
		Returns 0 <= n < (len(chunk0) + len(chunk1)).'''
	# http://wiki.multimedia.cx/index.php?title=ADTS
	chunk0, chunk1 = chunk0 or '', chunk1 or ''
	nn, n, n_offset, chunk_half = None, -1, None, len(chunk0) // 2
	chunk = chunk0 + chunk1
	for m in xrange(len(chunk)):
		n = chunk.find('\xff', n+1)
		if n == -1: break
		if ord(chunk[n+1]) >> 4 != 0xf: continue
		n_offset_new = abs(chunk_half - n)
		if n_offset is None or n_offset_new < n_offset: nn, n_offset = n, n_offset_new
		else: break
	else: raise RuntimeError(chunk)
	if nn is None:
		log.debug('Failed to find ADTS frame header in supplied chunks')
		nn = chunk_half
	return nn


filename_subs = {
	r'[\\/]': '_', r'^\.+': '_', r'[\x00-\x1f]': '_', r':': '-_',
	r'<': '(', r'>': ')', r'\*': '+', r'[|!"]': '-', r'[\?\*]': '_',
	'[\'â€™]': '', r'\.+$': '_', r'\s+$': '', r'\s': '_' }
filename_subs = list(
	(re.compile(k), v) for k,v in filename_subs.viewitems() )

def filename_process(name):
	for sub_re, sub in filename_subs: name = sub_re.sub(sub, name)
	return name

def ts_format(fmt=None, ts=None):
	if not fmt: return ''
	if not ts: ts = datetime.now()
	return ts.strftime(fmt)


def main(args=None):
	import argparse
	parser = argparse.ArgumentParser(
		description='Follow specified icy (shoutcast/icecast/*cast)'
				' stream and dump individual tracks from it to a separate files.')
	parser.add_argument('url', help='URL of an http stream to process.')
	parser.add_argument('-d', '--dir', metavar='path',
		help='Directory to store tracks in (default: current dir).')
	parser.add_argument('-f', '--filename-format',
		metavar='format', default='{ts_start}__{n:03d}__{ts}__{name}.mp3',
		help='Filename template to use for each track (default: %(default)r).')
	parser.add_argument('-t', '--ts-format',
		metavar='strftime_format', default='%Y%m%d-%H%M%S',
		help='Format to use for timestamps in --filename-format'
			' (as parsed by datetime.strftime in python, default: %(default)s).')
	parser.add_argument('-x', '--cut-on-meta-blocks', action='store_true',
		help='Assume that media blocks always belong to track in the following icy-meta.'
			' Seem to be the case with at least some online radios.')
	# parser.add_argument('-c', '--convert', action='store_true',
	# 	help='Convert each track to ogg in the background after it is stored.')
	parser.add_argument('--debug', action='store_true', help='Verbose operation mode.')
	opts = parser.parse_args(sys.argv[1:] if args is None else args)

	global log
	import logging
	logging.basicConfig(level=logging.DEBUG if opts.debug else logging.WARNING)
	log = logging.getLogger()

	if opts.dir: os.chdir(os.path.expanduser(opts.dir))

	r = requests.get(opts.url, headers={'Icy-MetaData': '1'}, stream=True)
	r.raise_for_status()
	bs = int(r.headers.get('icy-metaint') or 0)
	if not bs:
		p('HTTP response is missing "icy-metaint" header, aborting.')
		pp(dict(response=dict(code=r.status_code, headers=dict(r.headers.items()))))
		return 1
	log.debug('icy-metaint block size: %dB', bs)

	with closing(r):
		ts_start = ts_format(opts.ts_format)
		title_err_streak, title_err_streak_max = 0, 10
		title = title_new = chunk = chunk_new = None
		dst, dst_buff, dst_n, dst_n_iter = None, deque(), 0, iter(xrange(1, 2**30))

		title_changed = Event()
		signal.signal(signal.SIGQUIT, lambda sig,frm: title_changed.set())

		try:
			while True:
				chunk_new = r.raw.read(bs)

				if not title_changed.is_set(): dst_buff.append(chunk_new)
				else:
					if not title_new:
						title_new = '{} [#{:03d}]'.format(re.sub(r'^(.*) \[#\d+\]$', r'\1', title), dst_n)
					log.info('Detected stream title change: %r -> %r', title, title_new)
					if not opts.cut_on_meta_blocks: n = 0
					else: n = find_frame_n(chunk, chunk_new)
					if n >= len(chunk):
						dst_buff.append(chunk)
						n = n - len(chunk)
						chunk, chunk_new = chunk_new[:n], chunk_new[n:]
						dst_buff.append(chunk)
					else:
						chunk, chunk_new = chunk[:n], chunk[n:] + chunk_new
						dst_buff.append(chunk)
					title, chunk = title_new, None
					title_changed.clear()

				if dst_buff and dst:
					while dst_buff: dst.write(dst_buff.popleft())
				if chunk is None and title is not None:
					if dst: dst.close()
					dst_n = next(dst_n_iter)
					dst = open(
						opts.filename_format.format( ts_start=ts_start, n=dst_n,
							ts=ts_format(opts.ts_format), name=filename_process(title) ), 'wb' )
				chunk = chunk_new

				title_new_bs = ord(r.raw.read(1)) * 16
				title_new = r.raw.read(title_new_bs).rstrip('\0')
				if title_new:
					m = re.search(r'\bStreamTitle=\'(.*?)\';', title_new)
					if not m:
						log.error( 'Failed to process stream'
							' title block (len: %dB): %r', title_new_bs, title_new )
						title_err_streak += 1
						if title_err_streak > title_err_streak_max:
							p('Too many title-parsing errors in a row - probably a desync issue, aborting')
							return 1
						continue
					else: title_new, title_err_streak = m.group(1), 0
					if title_new != title: title_changed.set()

		finally:
			if dst: dst.close()

if __name__ == '__main__': sys.exit(main())
