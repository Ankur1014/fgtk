#!/usr/bin/env python
# -*- coding: utf-8 -*-

import argparse
parser = argparse.ArgumentParser()
parser.add_argument('-n', '--dry-run', action='store_true', help='Dry-run mode.')
parser.add_argument('-v', '--verbose', action='store_true', help='Verbose rsync.')
parser.add_argument('--debug', action='store_true', help='Dump a lot of debug info.')
optz = parser.parse_args()

import logging
logging.basicConfig( level='DEBUG'\
	if optz.debug else 'WARNING' )
log = logging.getLogger()

import itertools as it, operator as op, functools as ft
from subprocess import Popen, PIPE, STDOUT
from collections import defaultdict, MutableMapping
from glob import iglob
from copy import copy
from os.path import normpath, join
from tempfile import NamedTemporaryFile
import os, sys, re


ufs_del_mark = '_HIDDEN~'
ufs_path_del = '/srv/ufs/buffer/.unionfs'
ufs_path_chunk = '/chunk{}'
ufs_path_csync2 = '/etc/csync2_ufs*.cfg'
ufs_path_rsync_auth = '/etc/rsyncd.auth'
ufs_sync_remote = 'ufs@{}::ufs-update'
ufs_sync_local = '/srv/ufs'


class UfsChunkMap(object):

	def __init__(self):
		self._hosts, ufs_map = dict(), dict()
		ufs_chunk_num_re = re.compile(ufs_path_csync2.replace('*', '(\d+)'))
		for path in iglob(ufs_path_csync2):
			chunk_num = ufs_chunk_num_re.search(path)
			if chunk_num is None:
				log.warn( 'Non-numeric ufs chunk number detected in filename,'
					' matching ufs-chunk glob pattern ({}): {}'.format(ufs_path_csync2, path) )
				continue
			chunk_num = int(chunk_num.group(1))
			with open(path, 'rb') as cfg:
				cfg_iter = it.imap(str.strip, iter(cfg.readline, ''))
				for line in cfg_iter:
					if line.startswith('#'):
						path_buff = line.split()[1:]
						for line in it.imap(str.split, cfg_iter):
							if line[0].startswith('#'): path_buff += line[1:]
							else:
								if line[0] == 'group':
									hosts = list()
									for line in it.ifilter(None, (line.rstrip(';').split() for line in cfg_iter)):
										if line[0] == 'host': hosts.extend(line[1:])
										elif line[0] == '}': break
									ufs_map[chunk_num] = path_buff
									self._hosts[chunk_num] = hosts
								break

		self._tree = list(), dict()
		for chunk, path_buff in sorted(ufs_map.viewitems(), key=op.itemgetter(0)):
			for path_slugs in (filter( None,
					path.strip(os.sep).split(os.sep) ) for path in path_buff):
				chunks, anchor = self._tree
				slug = None
				for slug in path_slugs:
					anchor_prev = anchor
					try: chunks, anchor = anchor[slug]
					except KeyError:
						anchor[slug] = copy(chunks), dict()
						chunks, anchor = anchor[slug]
				if not anchor:
					if slug: anchor_prev[slug] = [chunk], anchor
					else: self._tree = [chunk], anchor
				elif chunk not in chunks: chunks.append(chunk)

		if optz.debug:
			from pprint import pformat
			log.debug('Chunk map:\n{}'.format(pformat(self._tree)))

	def __getitem__(self, slugs):
		chunks, anchor = self._tree
		for slug in slugs:
			try: chunks, anchor = anchor[slug]
			except KeyError: break
		return list((chunk_num, self._hosts[chunk_num]) for chunk_num in chunks)


def del_list():
	proc = Popen(
		['find', '-depth', '-type', 'f', '-name', '*{}'.format(ufs_del_mark)],
		stdout=PIPE, cwd=ufs_path_del )
	paths, real_paths = list(), list()
	for line in proc.stdout:
		line = line.strip().split(os.sep)
		if line[0] != '.' or not line[-1].endswith(ufs_del_mark):
			log.warn('Weird find output line: {}, skipping'.format(line))
			continue
		line = line[1:]
		real_paths.append(line)
		line[-1] = line[-1].rsplit(ufs_del_mark, 1)[0]
		paths.append(line)
	proc.wait()
	return paths, real_paths

def del_clean(paths):
	for slugs in paths:
		path = join(ufs_path_del, *slugs) + ufs_del_mark
		log.debug('Removing file: {}'.format(path))
		if not optz.dry_run: os.unlink(path)
	if not optz.dry_run:
		Popen(
			['find', '-type', 'd', '-empty', '-delete'],
			cwd=ufs_path_del ).wait()


def rsync_filter(*patterns):
	patterns = map(normpath, patterns)
	includes, excludes = set(), [b'*']
	for pat in patterns:
		pat = pat.lstrip(os.sep)
		slugs = pat.split(os.sep)
		for slug in range(1, len(slugs)):
			includes.add(join(os.sep, *slugs[:slug]) + os.sep)
		includes.add(join(os.sep, *slugs))
	includes = sorted(includes, key=len)
	return b'\n'.join(it.chain(
		it.imap(ft.partial(op.add, b'+ '), includes),
		it.imap(ft.partial(op.add, b'- '), excludes) ))


def sync_removals():
	chunk_map = UfsChunkMap()
	self_host = os.uname()[1]

	host_paths = defaultdict(set)
	sync_paths, del_paths = del_list()
	for path in sync_paths:
		chunks = chunk_map[path]
		if not chunks:
			log.warn('No destination chunk defined for path: {}, skipping'.format(path))
			continue
		chunk_num, hosts = chunks[0]
		host = None if self_host in hosts else hosts[0]
		dst = join(*path)
		log.debug('sync (ufs{}): /{} -> {}'.format(chunk_num, dst, host))
		host_paths[host].add(join(ufs_path_chunk.format(chunk_num), dst))

	with NamedTemporaryFile(dir='/tmp', prefix='.rsync.passwd.') as password_file:
		if set(host_paths).difference([None]):
			with open(ufs_path_rsync_auth, 'rb') as auth:
				for line in it.ifilter(None, it.imap(str.strip, auth)):
					user, password = line.split(':', 1)
					if user == 'ufs':
						password_file.write('{}\n'.format(password))
						password_file.flush()
						break
				else:
					raise KeyError( 'Unable to find rsync'
						' password for ufs user in {}'.format(auth.name) )
		for host, paths in host_paths.viewitems():
			# log.debug('Rsync filter for host {}:\n{}'.format(host, rsync_filter(*paths)))
			cmd = ['rsync', '-rcl', '--delete', '--filter=merge -']
			if host: cmd.append('--password-file={}'.format(password_file.name))
			if optz.dry_run: cmd.append('--dry-run')
			if optz.verbose: cmd.append('-v')
			cmd.extend(['/var/empty/.', '{}/.'.format(
				ufs_sync_remote.format(host) if host is not None else ufs_sync_local )])
			log.debug('Rsync command: {}'.format(cmd))
			proc = Popen(cmd, stdin=PIPE, stdout=PIPE, stderr=STDOUT)
			proc.stdin.write(rsync_filter(*paths))
			proc.stdin.close()
			for line in proc.stdout:
				if not optz.verbose\
					and line.startswith('cannot delete non-empty directory:'): continue
				sys.stderr.write(line)
			err = proc.wait()
			if err:
				raise RuntimeError('Rsync process failed with status: {}'.format(err))

	del_clean(del_paths)

	if not optz.dry_run and os.listdir(ufs_path_del):
		proc = Popen(['find'], stdout=PIPE, cwd=ufs_path_del)
		log.warn(
			'Unable to flush following paths (dir: {}):\n{}'\
			.format(ufs_path_del, proc.stdout.read()) )
		proc.wait()


sync_removals()
